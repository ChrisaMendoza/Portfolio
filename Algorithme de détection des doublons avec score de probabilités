{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9709d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be38b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Aper√ßu de df_events :\n",
      "                                                name  \\\n",
      "0                             \\tSam Divine in London   \n",
      "1                   Adam Hopkins: Sorry, What? (WIP)   \n",
      "2   AC13 & REAPER Present: Alpha Omega [Live Visual]   \n",
      "3                        ALTERIA @Legend Club Milano   \n",
      "4            Billige Gala - Musik, Talk & Feminismus   \n",
      "\n",
      "                                         description  \\\n",
      "0  Powerhouse & internationally renowned DJ, Sam ...   \n",
      "1  Adam Hopkins' new work in progress show about ...   \n",
      "2  ALPHA OMEGA: When Titans Collide ‚Äì AC13 & REAP...   \n",
      "3  üé∏ **ALTERIA** - \"Nel Fiore dei tuoi Danni\" LIV...   \n",
      "4  dq agency & rausgegangen pr√§sentieren: Die Bil...   \n",
      "\n",
      "                               venue_id     local_start_date  \\\n",
      "0  44842457-b062-4d8f-af32-86d27b78ab26  2025-04-05 20:00:00   \n",
      "1  9d201ec9-968f-4288-b691-ff68e96995cd  2025-03-06 21:45:00   \n",
      "2  63875860-f2f7-4a95-833c-89e159025bca  2025-02-21 22:00:00   \n",
      "3  efbee498-a516-4eff-ba06-cbbe99e0de9a  2025-04-22 18:00:00   \n",
      "4  10aff182-df20-4ebf-827c-917601d39c34  2025-03-13 18:00:00   \n",
      "\n",
      "        local_end_date  \n",
      "0  2025-04-06 03:00:00  \n",
      "1  2025-03-06 22:45:00  \n",
      "2  2025-02-22 03:00:00  \n",
      "3  2025-04-22 22:00:00  \n",
      "4  2025-03-14 00:00:00  \n",
      "\n",
      " Aper√ßu de df_venues :\n",
      "                                     id  \\\n",
      "0  00030a20-7fff-45e4-8899-cf31283d63cd   \n",
      "1  0006206c-b8b6-4a47-b566-90c992d3a241   \n",
      "2  00075c3d-9f0b-4cee-87b8-5561f02eb2fe   \n",
      "3  0012580c-ca02-4f18-aedc-e67b737ae73e   \n",
      "4  001ce403-56be-4c30-af4b-9989193ed9f1   \n",
      "\n",
      "                                     name  description  maximum_capacity  \\\n",
      "0  Th√©√¢tre G√©rard Philipe - Salle R. Blin          NaN                 0   \n",
      "1           Biblioth√®que Germaine Tillion          NaN                 0   \n",
      "2           La Briqueterie - Schiltigheim          NaN                 0   \n",
      "3                 Th√©√¢tre de la Madeleine          NaN                 0   \n",
      "4                     Silverworks Island           NaN                 0   \n",
      "\n",
      "                                  address          city postal_code  \\\n",
      "0               59 Boulevard Jules Guesde   SAINT-DENIS       93200   \n",
      "1           6 rue du Commandant Schl≈ìsing         Paris       75116   \n",
      "2        Avenue de la 2e Division Blind√©e  SCHILTIGHEIM       67300   \n",
      "3                        19 Rue de Sur√®ne         Paris       75008   \n",
      "4  Silvertown Square, Royal Victoria Dock        London     E16 1UR   \n",
      "\n",
      "  country_code  longitude  latitude  \n",
      "0           FR   2.350310   48.9382  \n",
      "1           fr   2.284600   48.8618  \n",
      "2           FR   7.730700   48.6101  \n",
      "3           fr   2.320320   48.8708  \n",
      "4           gb   0.027626   51.5046  \n",
      "\n",
      " Aper√ßu de df_venues_addresses :\n",
      "                    name  description  maximum_capacity company_id  \\\n",
      "0  √©glise du sacr√©-coeur          NaN                 0          0   \n",
      "1         √òresundsparken          NaN                 0          0   \n",
      "2           √î Totem Live          NaN                 0          0   \n",
      "3           √î TOTEM LIVE          NaN                 0          0   \n",
      "4         √î Boudoir Lyon          NaN                 0          0   \n",
      "\n",
      "                             address_id                                    id  \\\n",
      "0  438bf39c-6af3-4b19-87a0-133a8d50ae4d  2bc0c07a-7396-4e37-9a62-0884e51d53ee   \n",
      "1  761b79a0-e92f-4b9a-98a0-48cc3f690ca3  6803de10-3daa-445f-869b-b84e2972714d   \n",
      "2  e62278cf-6144-405b-b47e-ae4a45f78a2b  e189fd5b-aebd-4b8e-88c5-8da1cf8bc3b9   \n",
      "3  f1c90c33-f155-455a-adfe-eada1295a604  38d061bd-0752-43d4-a023-39ee8870fbc9   \n",
      "4  2af98409-710d-450e-9e6d-ba6c00a042d4  6751bb34-e5d4-46d6-afe9-f375a5f59bbf   \n",
      "\n",
      "   is_active           created_at  deleted_at  account_id  ...  state  \\\n",
      "0          1  2025-01-29 09:50:14         NaN         NaN  ...    NaN   \n",
      "1          1  2024-10-03 09:27:12         NaN         NaN  ...    NaN   \n",
      "2          1  2025-02-19 11:03:30         NaN         NaN  ...    NaN   \n",
      "3          1  2025-02-12 16:54:14         NaN         NaN  ...    NaN   \n",
      "4          1  2025-01-29 09:52:03         NaN         NaN  ...    NaN   \n",
      "\n",
      "   state_code  country  country_code latitude longitude  is_active.1  \\\n",
      "0         NaN      NaN           NaN  43.7732   7.49557            1   \n",
      "1         NaN      NaN            DK   0.0000   0.00000            1   \n",
      "2         NaN      NaN            fr  45.8142   4.90038            1   \n",
      "3         NaN      NaN           NaN  45.8142   4.90016            1   \n",
      "4         NaN      NaN           NaN  45.7521   4.82709            1   \n",
      "\n",
      "          created_at.1 deleted_at.1  managers  \n",
      "0  2025-01-29 09:50:13          NaN       NaN  \n",
      "1  2024-10-03 09:27:12          NaN       NaN  \n",
      "2  2025-02-19 11:03:30          NaN       NaN  \n",
      "3  2025-02-12 16:54:14          NaN       NaN  \n",
      "4  2025-01-29 09:52:03          NaN       NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# D√©finition des chemins des fichiers CSV\n",
    "file_events = \"event_cleaned_10000.csv\"\n",
    "file_venues = \"venues_cleaned.csv\"\n",
    "file_venues_addresses = \"venue_+_address_joined.csv\"\n",
    "\n",
    "# Charger les fichiers CSV\n",
    "df_events = pd.read_csv(file_events, encoding=\"utf-8\")\n",
    "df_venues = pd.read_csv(file_venues, encoding=\"utf-8\")\n",
    "df_venues_addresses = pd.read_csv(file_venues_addresses, encoding=\"utf-8\")\n",
    "\n",
    "# Aper√ßu des fichiers charg√©s\n",
    "print(\" Aper√ßu de df_events :\")\n",
    "print(df_events.head())\n",
    "\n",
    "print(\"\\n Aper√ßu de df_venues :\")\n",
    "print(df_venues.head())\n",
    "\n",
    "print(\"\\n Aper√ßu de df_venues_addresses :\")\n",
    "print(df_venues_addresses.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd4996",
   "metadata": {},
   "source": [
    "# Nettoyage des tables \"venue_+_address_joined.csv\", \"venues_cleaned.csv\" et \"event_cleaned_10000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70df01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de nettoyage des textes (nom, adresse, ville)\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip().lower()  # Supprimer espaces inutiles + mettre en minuscule\n",
    "        text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')  # Supprimer accents\n",
    "    return text\n",
    "#Standarisation des texts \n",
    "# Nettoyage des noms et adresses dans les 3 datasets\n",
    "df_events[\"name\"] = df_events[\"name\"].apply(clean_text)\n",
    "df_venues[\"name\"] = df_venues[\"name\"].apply(clean_text)\n",
    "df_venues[\"address\"] = df_venues[\"address\"].apply(clean_text)\n",
    "df_venues[\"city\"] = df_venues[\"city\"].apply(clean_text)\n",
    "df_venues_addresses[\"name\"] = df_venues_addresses[\"name\"].apply(clean_text)\n",
    "df_venues_addresses[\"address\"] = df_venues_addresses[\"address\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63506bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des latitudes et longitudes en float\n",
    "for df in [df_venues, df_venues_addresses]:\n",
    "    df[\"latitude\"] = pd.to_numeric(df[\"latitude\"], errors=\"coerce\")\n",
    "    df[\"longitude\"] = pd.to_numeric(df[\"longitude\"], errors=\"coerce\")\n",
    "\n",
    "# Suppression des valeurs aberrantes de latitude/longitude\n",
    "#On s‚Äôassure que les valeurs sont bien entre -90 et 90 pour la latitude, et -180 et 180 pour la longitude. \n",
    "#Si une coordonn√©e est invalide, les calculs de distance avec Geopy seront faux et peuvent donner des r√©sultats absurdes.\n",
    "#Le code supprime les lignes avec des coordonn√©es invalides\n",
    "for df in [df_venues, df_venues_addresses]:\n",
    "    df = df[(df[\"latitude\"].between(-90, 90)) & (df[\"longitude\"].between(-180, 180))]\n",
    "\n",
    "# Suppression des lignes o√π la latitude ou la longitude est null\n",
    "for df in [df_venues, df_venues_addresses]:\n",
    "    df.dropna(subset=[\"latitude\", \"longitude\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1e4e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nombre de lignes apr√®s nettoyage :\n",
      "df_events : 10000 lignes\n",
      "df_venues : 9941 lignes\n",
      "df_venues_addresses : 9941 lignes\n"
     ]
    }
   ],
   "source": [
    "print(f\"‚úÖ Nombre de lignes apr√®s nettoyage :\")\n",
    "print(f\"df_events : {len(df_events)} lignes\")\n",
    "print(f\"df_venues : {len(df_venues)} lignes\")\n",
    "print(f\"df_venues_addresses : {len(df_venues_addresses)} lignes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28fe832",
   "metadata": {},
   "source": [
    "# Code algorithme position g√©ographie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39643e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Aper√ßu du DataFrame fusionn√© :\n",
      "                                             name_x  \\\n",
      "0                              sam divine in london   \n",
      "1                  adam hopkins: sorry, what? (wip)   \n",
      "2  ac13 & reaper present: alpha omega [live visual]   \n",
      "3                       alteria @legend club milano   \n",
      "4           billige gala - musik, talk & feminismus   \n",
      "\n",
      "                                       description_x  \\\n",
      "0  Powerhouse & internationally renowned DJ, Sam ...   \n",
      "1  Adam Hopkins' new work in progress show about ...   \n",
      "2  ALPHA OMEGA: When Titans Collide ‚Äì AC13 & REAP...   \n",
      "3  üé∏ **ALTERIA** - \"Nel Fiore dei tuoi Danni\" LIV...   \n",
      "4  dq agency & rausgegangen pr√§sentieren: Die Bil...   \n",
      "\n",
      "                               venue_id     local_start_date  \\\n",
      "0  44842457-b062-4d8f-af32-86d27b78ab26  2025-04-05 20:00:00   \n",
      "1  9d201ec9-968f-4288-b691-ff68e96995cd  2025-03-06 21:45:00   \n",
      "2  63875860-f2f7-4a95-833c-89e159025bca  2025-02-21 22:00:00   \n",
      "3  efbee498-a516-4eff-ba06-cbbe99e0de9a  2025-04-22 18:00:00   \n",
      "4  10aff182-df20-4ebf-827c-917601d39c34  2025-03-13 18:00:00   \n",
      "\n",
      "        local_end_date                name_y  description_y  maximum_capacity  \\\n",
      "0  2025-04-06 03:00:00      electric brixton            NaN               0.0   \n",
      "1  2025-03-06 22:45:00       the bill murray            NaN               0.0   \n",
      "2  2025-02-22 03:00:00         clock factory            NaN               0.0   \n",
      "3  2025-04-22 22:00:00           legend club            NaN               0.0   \n",
      "4  2025-03-14 00:00:00  heimathafen neukolln            NaN               0.0   \n",
      "\n",
      "  company_id                            address_id  ...  state state_code  \\\n",
      "0          0  c6221259-4d10-4392-a1aa-0ea6e58b004e  ...    NaN        NaN   \n",
      "1          0  0061c4cf-25fc-45e2-8613-65ccaf6535cc  ...    NaN        NaN   \n",
      "2          0  0fe4f95b-9d80-45b1-934b-08d9bd770d1b  ...    NaN        NaN   \n",
      "3          0  b10f387d-f659-4cda-94da-367db30b37d7  ...    NaN        NaN   \n",
      "4          0  e0678d90-f818-4a0c-8fc0-cb12658015dc  ...    NaN        NaN   \n",
      "\n",
      "   country  country_code  latitude  longitude  is_active.1  \\\n",
      "0      NaN            gb   51.4598  -0.116868          1.0   \n",
      "1      NaN            gb   51.5363  -0.098821          1.0   \n",
      "2      NaN            gb   51.4557  -2.590620          1.0   \n",
      "3      NaN            it   45.5162   9.179270          1.0   \n",
      "4      NaN            de   52.4769  13.439300          1.0   \n",
      "\n",
      "          created_at.1 deleted_at.1 managers  \n",
      "0  2025-02-19 10:58:01          NaN      NaN  \n",
      "1  2025-02-19 10:57:39          NaN      NaN  \n",
      "2  2025-02-19 10:58:09          NaN      NaN  \n",
      "3  2025-02-19 10:58:07          NaN      NaN  \n",
      "4  2025-02-19 11:00:47          NaN      NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      " Suppression des NaN termin√©e !\n"
     ]
    }
   ],
   "source": [
    "# Renommer 'id' en 'venue_id' pour correspondre √† df_events\n",
    "df_venues_addresses.rename(columns={\"id\": \"venue_id\"}, inplace=True)\n",
    "\n",
    "# Faire la jointure sur 'venue_id'\n",
    "df_combined = df_events.merge(df_venues_addresses, on=\"venue_id\", how=\"left\")\n",
    "\n",
    "# V√©rifier si la jointure est bien faite\n",
    "print(\" Aper√ßu du DataFrame fusionn√© :\")\n",
    "print(df_combined.head())\n",
    "\n",
    "# Supprimer les lignes o√π latitude ou longitude est NaN\n",
    "df_combined = df_combined.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "print(\" Suppression des NaN termin√©e !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab034872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Colonnes de df_combined : ['name_x', 'description_x', 'venue_id', 'local_start_date', 'local_end_date', 'name_y', 'description_y', 'maximum_capacity', 'company_id', 'address_id', 'is_active', 'created_at', 'deleted_at', 'account_id', 'distributor_id', 'marketplace_url', 'extra', 'image_urls', 'id.1', 'address', 'details', 'city', 'postal_code', 'state', 'state_code', 'country', 'country_code', 'latitude', 'longitude', 'is_active.1', 'created_at.1', 'deleted_at.1', 'managers']\n"
     ]
    }
   ],
   "source": [
    "print(\" Colonnes de df_combined :\", df_combined.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a859be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir un seuil de distance (en km) pour consid√©rer un lieu comme un doublon\n",
    "SEUIL_KM = 0.5  # 500 m√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e41392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste pour stocker les doublons d√©tect√©s\n",
    "doublons = []\n",
    "\n",
    "# Comparer chaque lieu / √©v√©nement avec tous les autres\n",
    "for index1, row1 in df_combined.iterrows():\n",
    "    lat1, lon1 = row1[\"latitude\"], row1[\"longitude\"]\n",
    "    \n",
    "    for index2, row2 in df_combined.iterrows():\n",
    "        if index1 >= index2:  \n",
    "            continue  # √âviter les comparaisons en double\n",
    "        \n",
    "        lat2, lon2 = row2[\"latitude\"], row2[\"longitude\"]\n",
    "\n",
    "        # V√©rifier que les coordonn√©es sont bien des nombres\n",
    "        if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2):\n",
    "            continue  # Sauter cette comparaison si une valeur est NaN\n",
    "        \n",
    "        # Calculer la distance entre les deux points GPS\n",
    "        distance = geodesic((lat1, lon1), (lat2, lon2)).km\n",
    "\n",
    "        # V√©rifier si la distance est inf√©rieure au seuil\n",
    "        if distance < SEUIL_KM:\n",
    "            doublons.append((row1[\"name_x\"], row2[\"name_x\"], row1[\"venue_id\"], row2[\"venue_id\"], distance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d421ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les r√©sultats en DataFrame pour affichage\n",
    "df_doublons = pd.DataFrame(doublons, columns=[\"Nom 1\", \"Nom 2\", \"Venue_ID 1\", \"Venue_ID 2\", \"Distance (km)\"])\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "print(\"\\n Doublons d√©tect√©s :\")\n",
    "print(df_doublons) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae5744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
