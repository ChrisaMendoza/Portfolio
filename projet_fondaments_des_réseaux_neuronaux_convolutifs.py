# -*- coding: utf-8 -*-
"""Projet - Fondaments des réseaux neuronaux convolutifs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BtzAIT70o2qe-MG4i5peeuyEDXrJ-fB_

# **Projet : Classification d'images de chats et de chiens avec un modèle de réseaux de neurones convolutifs**

### Ce projet a été réalisé par :
- Chrisa Mendoza
- Flavie Kutu Kialanda
- Dhanajayan Annamale

# **Installation des bibliothèques nécessaires**
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
import os

"""# **Chargement et préparation des données**

**1** - Nous procédons au téléchargement du dataset cats_vs_dogs et à sa division en 2 ensembles :
- 80% pour l'entraînement ;
- 20% pour la validation.
"""

dataset = "cats_vs_dogs"
(ds_train, ds_val), info = tfds.load(
    dataset,
    split=['train[:80%]', 'train[80%:]'], # Divise en entraînement et validation
    as_supervised=True, # Les données sont retournées sous forme (image, label)
    with_info=True) # Charge les métadonnées du dataset

"""**2** - Pour avoir une idée visuelle des données, nous écrivons une fonction qui affiche un échantillon de 9 images avec leurs étiquettes.

Cela nous aide à vérifier la qualité et le contenu des données avant de les utiliser pour l'entraînement.
"""

class_names = info.features['label'].names # Retourne les noms de classes (Cat et Dog)

def show_examples(dataset, class_names):
    plt.figure(figsize=(10, 10))  # Taille de la grille
    for i, (image, label) in enumerate(dataset.take(9)):  # Prends les 9 premières images
        plt.subplot(3, 3, i + 1)  # Crée une grille 3x3
        plt.imshow(image.numpy().astype("uint8")) # Affiche l'image après conversion au format compatible
        plt.title(class_names[label.numpy()])  # Ajoute le titre basé sur l'étiquette
        plt.axis("off")  # Supprime les axes pour une meilleure lisibilité
    plt.show()

"""**3** - Enfin, nous allons afficher des exemples en utilisant notre fonction."""

show_examples(ds_train, class_names)

"""L'échantillon de 9 images avec leurs étiquettes ('cat' = chat et 'dog'= chien ) s'affiche.

On recense 6 images de chiens et 3 images de chats parmi les 9 premières images.

# **Prétraitement des données**

Une fois que nous avons chargé et préparé les données, il est temps de les prétraiter pour les rendre adaptées à l'entraînement du modèle.

**1** - Nous fixons la taille cible des images et la taille cible des lots (mini-batchs).
"""

IMG_SIZE = 128
BATCH_SIZE = 32

"""**2** - Nous allons par la suite créer une fonction de prétraitement qui redimensionne les images et normalise leurs pixels entre 0 et 1.


"""

def preprocess_image(image, label):
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE)) # Redimension des images à 128*128 pixels
    image = image / 255.0 # Ici, il y a la normalisation des pixels pour les ramner à un intervalle [0,1]
    return image, label

"""**3** - Ici, nous appliquons la fonction de prétraitement à chaque image du dataset et configurons le pipeline de données pour qu'il soit optimisé.

"""

ds_train = (ds_train
          .map(preprocess_image) # Application de la fonction preprocess_image à chaque image.
          .shuffle(1000) # Mélange les données pour l'entraînement
          .batch(BATCH_SIZE) # Regroupe les images en lots de taille BATCH_SIZE.
          .prefetch(tf.data.AUTOTUNE)) # Optimise le chargement

ds_val = (ds_val
          .map(preprocess_image)
          .batch(BATCH_SIZE)
          .prefetch(tf.data.AUTOTUNE))

"""À ce stade, nos données sont prêtes à être utilisées pour entraîner un modèle de deep learning.

# **Création du modèle CNN**

Ici, nous visons à créer un modèle simple avec plusieurs couches convolutives.

**1** - Nous commençons par définir la structure du modèle.
"""

model = models.Sequential()

# Ajouter des couches convolutives et de pooling
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))

"""**2** - On aplatit les caractéristiques 2D et les connecte au classificateur dense."""

model.add(layers.Flatten()) # On transforme les données 2D en un vecteur 1D
model.add(layers.Dense(128, activation='relu')) # On ajoute une couche dense avec 128 unités et une activation 'ReLu'
model.add(layers.Dense(1, activation='sigmoid')) # On termine avec une couche dense de sortie avec une activation 'sgimoid' pour la classification binaire

"""**3** - On compile le modèle produit."""

model.compile(optimizer='adam', # optimiseur
              loss='binary_crossentropy', # fonction de perte
              metrics=['accuracy']) # métriques

"""**4** - Enfin, nous affichons un résumé textuel de notre modèle."""

model.summary()

"""# **Entraînement du modèle**

Dans cette partie, nous allons entraîner le modèle avec les données prétraitées.

**1** - Nous fixons le nombre d’époques d'entraînement à 10.

Cela permet au modèle d’apprendre progressivement sans trop surcharger l’entraînement.
"""

EPOCHS = 10

"""**2** - Nous appelons la méthode fit pour entraîner le modèle.

Elle permet aussi d'ajuster les paramètres internes en fonction des données d'entrée, et de l'optimiser pour effectuer des prédictions plus précises. L'entraînement du modèle a duré 2h30min.
"""

history = model.fit(ds_train, validation_data=ds_val, epochs=EPOCHS)

"""**3** - Enfin, nous allons sauvegarder l’historique d’entraînement dans une variable 'history'."""

print(history.history.keys())

"""# **Évaluation et visualisation des résultats**

Dans cette partie, nous cherchons à afficher les courbes de perte et de précision de notre modèle.

**1** - Nous préparons la visualisation des courbes.
"""

plt.figure(figsize=(12, 6))

"""**2** - Nous traçons la courbe de précision.

**3** - Nous traçons la courbe de perte.

**4** - Nous ajoutons des légendes et des titres aux courbes.

**5** - Nous affichons les courbes de précision et de perte.
"""

# Visualisation de la courbe de précision
a = plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Précision entraînement')
plt.plot(history.history['val_accuracy'], label='Précision validation')
plt.legend()
plt.title('Courbe de Précision')

# Visualisation de la courbe de perte
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Perte entraînement')
plt.plot(history.history['val_loss'], label='Perte validation')
plt.legend()
plt.title('Courbe de Perte')
plt.show()

"""# **Test sur de nouvelles images**

Dans cette section, nous testons le modèle sur des images externes.

**1** - Nous importons les bibliothèques nécessaires au test.
"""

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import tensorflow as tf
from google.colab import files

"""**2** - On définit la fonction predict_image qui effectue une prédiction à partir d'une image."""

def predict_image(image_path):
    # On charge et redimensionner l'image
    img = Image.open(image_path)
    img = img.resize((128, 128))
    # On convertit l'image en tableau numpy et on normalise
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    # On effectue la prédiction
    prediction = model.predict(img_array)
    # On vérifie la classe prédite
    if prediction[0][0] > 0.5: # [0][0] récupére la probabilité si le modèle est binaire
        prediction_label = 'Chien'
    else:
        prediction_label = 'Chat'
    # On affiche l'image avec la prédiction
    plt.imshow(img)
    plt.title(f'Prédiction : {prediction_label}')
    plt.axis('off')
    plt.show()

"""**3** - On importe et on téléverse une image que le modèle va tester."""

uploaded = files.upload()
image_path = next(iter(uploaded))

"""**4** - On appelle la fonction 'predict_image', qui effectue la prédiction sur l'image chargée.

Enfin, on affiche son résultat de prédiction.
"""

predict_image(image_path)

"""La prédiction est juste : c'est bien une image de chien que nous apercevons avec l'étiquette correspondante 'Chien'.

# **Conclusion**

Ce projet nous a permis de découvrir comment gérer un travail de classification d'images. Nous avons commencé par charger le dataset et préparer les images en les redimensionnant et en les normalisant pour qu'elles soient prêtes à être utilisées par notre modèle.

Ensuite, nous avons construit un modèle de réseau de neurones convolutifs (CNN) assez simple et nous l'avons entraîné pour qu'il puisse apprendre à reconnaître des chiens et des chats. Enfin, nous avons testé notre modèle sur de nouvelles images pour voir s'il était capable de faire des prédictions correctes.

Pour conclure, ce projet nous a permis de passer de la gestion des données à l’évaluation des performances de notre modèle, en suivant les étapes classiques d’un projet d'apprentissage supervisé.

**Chrisa MENDOZA**

**Flavie KUTU KIALANDA**

**Dhanajayan ANNAMALE**

*Groupe B3-2*
"""